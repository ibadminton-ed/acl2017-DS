\section{Curriculum Learning based Training \label{sec:training}}
%Training with Curriculum Learning??
%\blue{we talk about the difficulty of training with $\sum_{i=1}^N{-log(o_{iy_{i}}) } + \beta trace(\mathbf{T}_{i})$  first. 1) noisy data, 2) local optima. Therefore, we need CL. The advantages are 1) learn to model with noise gradually, 2) more robust, avoid local optima, 3) have a chance to control the effect of noise via Trace norm.  }

One of the key challenges of this work is  on how to train and produce the transition matrix to model the noise  in the training data without any direct guidance and human involvement.
A straightforward solution is to directly align the observed distribution, $\mathbf{o}$, with respect to the noisy labels by minimizing the sum of the two terms:
$CrossEntropy(\mathbf{o}) + Regularization$. However, doing so
does not guarantee that the prediction distribution, $\mathbf{p}$, will match the true relation distribution.
The problem is at the beginning of the training, we have no prior knowledge about the noise pattern, 
thus, both  $\mathbf{T}$ and $\mathbf{p}$ are less reliable, making the training procedure be likely to trap into some poor local optimum.
Therefore, we require a technique to guide our model to gradually adapt to the noisy training data, e.g., learning something simple first, and then trying to deal with noises.

Fortunately, this is exactly what curriculum learning can do.
The idea of curriculum learning~\cite{bengio2009curriculum} is simple: starting with the easiest aspect of a task, and leveling up the difficulty gradually,
which fits well to our problem.
We thus employ a curriculum
learning framework to guide our model to gradually learn how to characterize the noise. 
% and how to control its effect via trace regularization, while 
Another advantage is to avoid falling into poor local optimum.
%when there is little knowledge about the noise pattern. 


By exploiting curriculum learning, our approach  provides the
flexibility to combine prior knowledge of noise, e.g., splitting a dataset into reliable and less reliable subsets,  to improve the
effectiveness of  the transition matrix and better model the noise.
%We show that if one could break the
%dataset into reliable and less reliable parts, our approach can exploit the split
%as indirect supervision over the noise pattern to build more effective
%transition matrix to better model the noise. 
%The sum is greater than its parts.
%As shown later in Section~\ref{sec:evaluation}, putting together these techniques
%enables us to build an adaptive scheme to better model the noise pattern over the state-of-the-art.



%Furthermore, if we have prior knowledge to roughly separate the data into reliable and less reliable subsets, we can utilize the split as indirect supervisions over the noise pattern to help the transition matrix to better model the noise.
%Apart from that, we also show how to constrain the \red{ability??} of the transition matrix to avoid \red{overfitting???}.

\subsection{Trace Regularization}
Before proceeding to training details, we first discuss how we characterize the noise level of the data by controlling the trace of its transition matrix.
Intuitively, if the noise is small, the transition matrix $\mathbf{T}$ will tend to become an identity matrix, i.e., given a set of annotated training sentences,  the observed relations and their true relations are almost identical. Since each row of $\mathbf{T}$ sums to 1, the similarity between the transition matrix and the identity matrix can be represented by its trace, $trace (\mathbf{T})$. The larger the $trace(\mathbf{T})$ is, the larger the diagonal elements are, and the more similar the transition matrix $\mathbf{T}$ is to the identity matrix, indicating a lower level of noise. Therefore, we can characterize  the noise pattern by controlling the expected value of $trace(\mathbf{T})$ in the form of regularization. For example, we will expect a larger $trace (\mathbf{T})$ for reliable data, but  a smaller $trace(\mathbf{T})$  for less reliable data. Another advantage of employing trace regularization is that it could help reduce the model complexity  %since we have so many parameters (each data has a TM),
and avoid overfitting.

%\subsection{Curriculum Learning}
%The idea of curriculum learning is simple: starting with the easiest aspect of a task, and leveling up the difficulty gradually, which fits well with our problem.
%There are situations where we may have prior knowledge of the data quality and situations where we do not.
%Curriculum learning performs well in both scenarios.

\subsection{Training}
%\paragraph{Without Prior Knowledge of Data Quality}
To tackle the challenge of no direct guidance over the noise patterns,
%i.e., $\mathbf{p}$ does not guarantee to match the true relation distribution,
we implement a curriculum learning based training method to
%a straightforward idea is to
first train the model without considerations for noise. In other words, we first focus on the loss from the prediction distribution $\mathbf{p}$ ,  and then take the noise modeling into account gradually along the training process, i.e., gradually increasing the importance of the loss from the observed distribution $\mathbf{o}$ while decreasing the importance of $\mathbf{p}$. In this way, the prediction branch is roughly trained before the model managing to characterize the noise, thus avoids being stuck into poor local optimum.
%We implement this idea in the curriculum learning framework, and,  specifically,
%we consider ignoring the noise is the easier part of training compared with modeling the noise, and our
We thus design to minimize  the following loss function:
%
%If no guidance over the noise pattern exists, using only $\mathbf{o}$ to match the noisy label does not guarantee $\mathbf{p}$ to match the true relation distribution. Therefore, we use the linear combination of the cross entropy of both $\mathbf{o}$ and $\mathbf{p}$ as our objective function. Furthermore, we build a curriculum by controlling the training objective to gradually emphasis on noise modeling. Specifically, we design a decreasing weighting scheme for both the cross entropy of output prediction and the trace regularization component:
%\red{ gradually controlling the impact of the transition matrix}. Specifically, \red{we design a decreasing weighting scheme for the trace regularization component}, defined as:
%
\begin{equation}
\begin{aligned}
L&=\sum_{i=1}^N{-((1-\alpha) log(o_{iy_{i}}) + \alpha log(p_{iy_{i}}))} \\
&- \beta trace(\mathbf{T}^{i})
\end{aligned}
\label{general_loss}
\end{equation}
where 0$<$$\alpha$$\le$1 and $\beta$$>$0 are two weighting parameters, $y_i$ is the relation assigned by \DS for the $i$-th  instance, $N$ the total number of training instances, $o_{iy_{i}}$ is the probability that the observed relation for the $i$-th instance is $y_i$, and $p_{iy_{i}}$ is the probability to predict relation $y_i$ for the $i$-th instance.
%and $p_{iy_{i}}$ are the probabilities that the observed and predicted relations for the $i$-th instance are $y_i$ respectively.
%Instead of using the observed relation distribution $\mathbf{o}$ only to simulate the relation labeled by \DS, we use the linear combination of the cross entropy of both the observed relation distribution $\mathbf{o}$ and the predicted relation distribution $\mathbf{p}$. \blue{do we need a reason or two?}

Initially, we set $\alpha$=1, and train our model  completely by minimizing the loss from the prediction distribution $\mathbf{p}$. That is, we do not expect to model the noise,  but focus  on the prediction branch at this time. As the training progresses, the prediction branch gradually learns the basic prediction ability. We then decrease $\alpha$ and  $\beta$ by 0$<$$\rho$$<$1 ($\alpha^*$=$\rho$$\alpha$ and $\beta^*$=$\rho$$\beta$) every $\tau$ epochs, i.e., learning more about the noise from the observed distribution $\mathbf{o}$ and allowing a relatively smaller $trace(\mathbf{T})$ to accommodate more noise.
% , to gradually shift part of our focus to \orange{noise modeling.} 
%\red{learning with noise}. 
The motivation behind is to put more and more effort on learning the noise pattern as the training proceeds, 
with the essence of curriculum learning.
This gradually learning paradigm significantly distinguishes from prior work on noise modeling for \DS seen to date. 
Moreover, as such a method does not rely on any extra assumptions,
it can serve as our default training method for $\mathbf{T}$.

\paragraph{With Prior Knowledge of Data Quality}
On the other hand, if we happen to have prior knowledge about which part of the training data is more reliable and which is less reliable, we can utilize this knowledge as guidance to design the curriculum.  
%over the noise patterns \red{by helping the model to distinguish reliable data from less reliable ones (DO WE actually distinguish them??)} \orange{yes, with trace reg, and indirectly with CL as well}. 
Specifically, we can build a curriculum by first training the prediction branch on the reliable data for several epochs, and then adding the less reliable data to train the full model. In this way, the prediction branch is roughly trained before exposed to more noisy data, thus is less likely to fall into poor local optimum.

Furthermore, we can take better control of the training procedure by using trace regularization, e.g., encouraging larger $trace (\mathbf{T})$ for reliable subset and smaller $trace (\mathbf{T})$ for less relaibale ones.
%\red{utilize our prior knowledge of the data quality in the form of trace regularization}.
Specifically, we propose to minimize the following  loss function:
%
\begin{equation}
\begin{aligned}
L=\sum_{m=1}^M{\sum_{i=1}^{N_m}{-log(o_{mi,y_{mi}})}} - \beta_m trace(\mathbf{T}^{mi})
\end{aligned}
\end{equation}
where $\beta_m$ is the regularization weight for the $m$-th data subset, $M$ is the total number of subsets, $N_m$ the number of instances in $m$-th subset, and  $\mathbf{T}^{mi}$, $y_{mi}$ and $o_{mi,y_{mi}}$ are the transition matrix, the relation labeled by \DS and the observed probability of this relation for the $i$-th training instance in the $m$-th subset, respectively. Note that different from Equation~\ref{general_loss}, this loss function does not need to initiate training by
minimizing the loss regarding the prediction distribution $\mathbf{p}$, since one can easily start by learning from the most reliable split first. 

%since we have indirect guidance over noise pattern here. Specifically, trace regularization can utilize the prior konwledge of data quality by using different weights to serve as indirect guidance over noise pattern. Therefore,  
%\orange{change the reason to trace reg?}

We also use trace regularization for the most reliable subset, since there are still some noise annotations inevitably appearing in this split. 
% For the most reliable subset, we also add a trace regularization, since there are still some noise annotations inevitably appearing in this split. 
Specifically, we expect its $trace(\mathbf{T})$ to be large (using a positive $\beta$) so that the elements of $\mathbf{T}$ will be centralized to the diagonal and $\mathbf{T}$ will be more similar to the identity matrix. As for the  less reliable subset, we expect the $trace (\mathbf{T})$ to be small (using a negative $\beta$) so that the elements of the transition matrix will be diffusive and $\mathbf{T}$  will be less similar to the identity matrix. In other words, the transition matrix is encouraged to characterize the noise.

Note that this loss function only works for sentence level models. For bag level models, since reliable and less reliable sentences are all aggregated into a sentence bag,  we can not determine which bag is reliable and which is not. However, bag level models can still build a curriculum by changing the content of a bag, e.g., keeping reliable sentences in the bag first, then gradually adding less reliable ones, and training with Equation~\ref{general_loss}, which could benefit from the prior knowledge of data quality as well.



%%%%%%%%%%%%%%%%%%%% omit for further journal publication  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%
%\subsection{Constrained Transition Matrix} \blue{DO we need special discussion for this one??}
%%%\orange{Since the triples in knowledge base are reliable in most of the times, the positive label confusion noise is less likely than the false negative and false positive noise.}
%\red{In most DS relation extraction cases,  the imperfect knowledge bases and the inexact alignments between seed knowledge facts and unstructured text lead to many  \textit{false negative} and \textit{false positive} instances, more severe compared to  the \textit{label confusions} issues among positive relations.
%%%the problems of \textit{false negative} and \textit{false positive} are more severe, compared to \textit{label confusions} among positive relations.
%%%The reasons are twofold. First, since the knowledge bases are usually far from perfect, the \DS generated negative data are often \textit{false negative}. And the inexact alignments between seed knowledge facts and unstructured text produces many  \textit{false positive} instances.
% }
%%%However our transition matrix has the ability to model all these three types of noise. To prevent overfitting and make the model \red{concentrate on the false negative and false positive noise??}\orange{(not sure about the problem)},
%We  thus restrict the transition matrix for bag level models to \blue{(why not sentence level?)} so that the diagonal, the first column and the first row of the transition matrix may not equal to zero\footnote{we assume that the index of \emph{No-Relation} is 0.}, \blue{acommodating  such noisy instances???}.
%%
%%
%%
%%%%%%%%%%%%%%%%%%%% omit for further journal publication  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%