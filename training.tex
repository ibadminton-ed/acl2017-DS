\section{Curriculum Learning based Training \label{sec:training}}  
%Training with Curriculum Learning??
%\blue{we talk about the difficulty of training with $\sum_{i=1}^N{-log(o_{iy_{i}}) } + \beta trace(\mathbf{T}_{i})$  first. 1) noisy data, 2) local optima. Therefore, we need CL. The advantages are 1) learn to model with noise gradually, 2) more robust, avoid local optima, 3) have a chance to control the effect of noise via Trace norm.  }

%One of the key innovations of this work is on how to train and generate the transition matrix.
One of the key challenges of this work is  on how train and produce the transition matrix to model the noise without any direct guidance in the training data. 
%The challenge here lies in the fact that we often do not have 
%The difficulty of training the transition matrix lies in that there is no 
%direct guidance over the noise pattern. 
A straightforward solution is to directly align the observed distribution, $\mathbf{o}$, with respect to the noisy annotations by minimizing:
$CrossEntropy(\mathbf{o}) + Regularization$, but doing so 
%
%This means that simply aligning the observed distribution, $\mathbf{o}$, with the noisy labels 
does not guarantee that the prediction distribution, $\mathbf{p}$, will match the true relation distribution.
% Because: 1) noisy data, 2) local optima.
One reasons is that at the beginning, we have no prior about the noise patterns, thus both  $\mathbf{T}$ and $\mathbf{p}$ are less reliable, which will make the training procedure fall into local optimum easily.  
\blue{Therefore, we need to guide our model to gradually adapt to the noisy training data, e.g., learning something simple first, and then trying to deal with noises.}

\blue{Fortunately, this is exactly what curriculum learning can do. 
The idea of curriculum learning is simple: starting with the easiest aspect of a task, and leveling up the difficulty gradually,
which fits well to our problem.} 
%There are situations where we may have prior knowledge of the data quality and situations where we do not.  Curriculum learning performs well in both scenarios.  
%
%To tackle this challenge, 

We thus employ a curriculum
learning framework to guide our model to gradually learn how to 
\red{characterize the noise and how to control its effect via trace regularization}, while avoiding falling into local optimum, 
%rather than modeling the noise at the very beginning of training 
when there is little knowledge about the noise pattern.
%
%\blue{The advantages are 1) learn to model with noise gradually, 2) more robust, avoid local optima, 3) have a chance to control the effect of noise via Trace norm.}
%
By exploring curriculum learning, our approach will  provide the
flexibility to combine any prior knowledge of noise to improve the
effectiveness of  the transition matrix. We show that if one could break the
dataset into reliable and less reliable parts, our approach can exploit the split
as indirect supervision over the noise pattern to build more effective
transition matrix to better model the noise. The sum is greater than its parts. 
As shown later in Section~\ref{sec:evaluation}, putting together these techniques
enables us to build an adaptive scheme to better model the noise pattern over the state-of-the-art. 



%Furthermore, if we have prior knowledge to roughly separate the data into reliable and less reliable subsets, we can utilize the split as indirect supervisions over the noise pattern to help the transition matrix to better model the noise.
%Apart from that, we also show how to constrain the \red{ability??} of the transition matrix to avoid \red{overfitting???}.

\subsection{Trace Regularization}
Before proceeding to training details, we first discuss how we characterize 
Intuitively, if the noise is small, the transition matrix $\mathbf{T}$ will tend to become an identity matrix, \blue{i.e., given a set of annotated training sentences,  the observed relations and their true relations are almost identical.}  Since each row of $\mathbf{T}$ sums to 1, the similarity between the transition matrix and the identity matrix can be represented by the trace of $\mathbf{T}$, $trace(\mathbf{T})$. The larger the $trace(\mathbf{T})$ is, the smaller the elements that do not lie in the diagonal are, and the more similar the transition matrix $\mathbf{T}$ is to the identity matrix. Therefore, we can characterize  the noise level of the data by controlling the \red{expected} value of $trace(\mathbf{T})$ in the form of regularization. For example, we will expect a larger $trace(\mathbf{T})$ for reliable data, but  a smaller $trace(\mathbf{T})$  for less reliable data. Another advantage of employing trace regularization is that it could helpful to reduce the model complexity,  %since we have so many parameters (each data has a TM), 
and avoid overfitting. 

%\subsection{Curriculum Learning}
%The idea of curriculum learning is simple: starting with the easiest aspect of a task, and leveling up the difficulty gradually, which fits well with our problem.
%There are situations where we may have prior knowledge of the data quality and situations where we do not. 
%Curriculum learning performs well in both scenarios.  

\subsection{Training}
%\paragraph{Without Prior Knowledge of Data Quality}
To tackle the challenge of no direct guidance over the noise patterns, 
%i.e., $\mathbf{p}$ does not guarantee to match the true relation distribution, 
we implement a curriculum learning based training method to  
%a straightforward idea is to 
first train the model without considerations for noise, i.e., focusing on the loss from the prediction distribution $\mathbf{p}$ ,  and then take the noise modeling into account gradually along the training process, i.e., gradually increasing the importance of the loss from the observed distribution $\mathbf{o}$ while decreasing the importance of $\mathbf{p}$. In this way, the prediction branch is roughly trained before the model managing to characterize the noise, thus avoids being stuck into local optimum. 
%We implement this idea in the curriculum learning framework, and,  specifically, 
%we consider ignoring the noise is the easier part of training compared with modeling the noise, and our 
We accordingly design to minimize  the following loss function:
%
%If no guidance over the noise pattern exists, using only $\mathbf{o}$ to match the noisy label does not guarantee $\mathbf{p}$ to match the true relation distribution. Therefore, we use the linear combination of the cross entropy of both $\mathbf{o}$ and $\mathbf{p}$ as our objective function. Furthermore, we build a curriculum by controlling the training objective to gradually emphasis on noise modeling. Specifically, we design a decreasing weighting scheme for both the cross entropy of output prediction and the trace regularization component:
%\red{ gradually controlling the impact of the transition matrix}. Specifically, \red{we design a decreasing weighting scheme for the trace regularization component}, defined as:
%
\begin{equation}
\begin{aligned}
Loss	&=\sum_{i=1}^N{-((1-\alpha) log(o_{iy_{i}}) + \alpha log(p_{iy_{i}}))} \\
&- \beta trace(\mathbf{T}^{i})
\end{aligned}
\label{general_loss}
\end{equation}
where $0>\alpha>1$ and $\beta>0\red{????????}$ are two weighting parameters, $y_i$ is the relation assigned by \DS for the $i$th training instance, $N$ the total number of training instances , $o_{iy_{i}}$ is the probability that the observed relation for the $i$th instance is $y_i$, and $p_{iy_{i}}$ is the probability that the predicted relation for the $i$th instance is $y_i$.
%and $p_{iy_{i}}$ are the probabilities that the observed and predicted relations for the $i$th instance are $y_i$ respectively. 
%Instead of using the observed relation distribution $\mathbf{o}$ only to simulate the relation labeled by \DS, we use the linear combination of the cross entropy of both the observed relation distribution $\mathbf{o}$ and the predicted relation distribution $\mathbf{p}$. \blue{do we need a reason or two?}

At the beginning, we set $\alpha=1$, and train our model  completely by minimizing the loss from the prediction distribution $\mathbf{p}$,  that is, we do not expect to model the noise,  but focusing  on the prediction branch at this time. As the training proceeds, the prediction branch gradually learns the basic prediction ability, we then increase the level by decreasing $\alpha$ and  $\beta$ by $0<\rho<1$ \todo{(need a formular? $\alpha=\alpha*(1-\rho)$??)} every $\tau$ epochs, i.e., learning more about the noise from the observed distribution $\mathbf{o}$ and allowing a relatively smaller $trace(\mathbf{T})$, to gradually shift part of our focus to 
%the noise modeling. 
%gradually guide our model to 
\red{learning with noise}. 
%

This curriculum learning based training method does not rely on any extra assumptions, 
%our method can actually apply to any situations, and therefore are considered as 
thus can serve as our default training method for $\mathbf{T}$.

\paragraph{With Prior Knowledge of Data Quality}
On the other hand, if we are lucky to have prior knowledge about which part of the training data is more reliable and which is less reliable, we can utilize this knowledge as an indirect guidance over the noise patterns \red{by helping the model to distinguish reliable data from less reliable ones (DO WE actually distinguish them??)}. Specifically, we can build a curriculum by first training the prediction branch on the reliable data for several epochs, and then adding the less reliable data to train the full model. In this way, the prediction branch is roughly trained before exposed to more noisy data, thus is less likely to fall into local optimum. 

Furthermore, we can take better control of the training procedure by using trace regularization, e.g., encouraging larger $trace(\mathbf{T})$ for reliable subset and smaller $trace(\mathbf{T})$ for less relaibale ones. 
%\red{utilize our prior knowledge of the data quality in the form of trace regularization}.
Specifically, we propose to minimize the following  loss function:
%
\begin{equation}
\begin{aligned}
Loss=\sum_{m=1}^M{\sum_{i=1}^{N_m}{-log(o_{miy_{mi}})}} + \beta_m \red{trace(\mathbf{T}^{mi})}
\end{aligned}
\end{equation}
where $\beta_m$ is the regularization weight for the $m$th data subset, $N_m$ is total number of instances in $m$th subset, and  $\mathbf{T}^{mi}$, $y_{mi}$ and $o_{miy_{mi}}$ are the transition matrix, the relation labeled by distant supervision and the observed probability for the $i$th training instance in the $m$th subset, respectively. Note that different from Equation~\ref{general_loss}, this loss function does not need to initiate the training procedure by 
minimizing the loss regarding the prediction distribution $\mathbf{p}$, since one can easily start by learning from the most reliable split first. 

For the reliable subset, we want $trace(\mathbf{T})$ to be large  \red{(negative $\beta$)} so that the element values of $\mathbf{T}$ will be centralized to the diagonal and $trace(\mathbf{T})$ will be more similar to the identity matrix. As for the  less reliable subset, we want the $trace(\mathbf{T})$ to be small \red{(positive $\beta$)} so that the element values of their transition matrices will be diffusive and the transition matrix will be less similar to the identity matrix. \blue{In other words, the transition matrix is encouraged to characterize the noise. }

Note that this loss function only works for sentence level models, since reliable sentences and less reliable ones are all aggregated into a sentence bag in the bag level models,  we therefore can not determine which bag is reliable and which is not. However, bag level models can still use the curriculum by changing the content of the bag, \red{e.g., keeping reliable sentences in the bag first and gradually adding less reliable ones,}  and use Equation~\ref{general_loss} for training. By doing so, it can benefit from the prior knowledge of data quality as well.



%%%%%%%%%%%%%%%%%%%% omit for further journal publication  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%
%\subsection{Constrained Transition Matrix} \blue{DO we need special discussion for this one??}
%%%\orange{Since the triples in knowledge base are reliable in most of the times, the positive label confusion noise is less likely than the false negative and false positive noise.} 
%\red{In most DS relation extraction cases,  the imperfect knowledge bases and the inexact alignments between seed knowledge facts and unstructured text lead to many  \textit{false negative} and \textit{false positive} instances, more severe compared to  the \textit{label confusions} issues among positive relations.
%%%the problems of \textit{false negative} and \textit{false positive} are more severe, compared to \textit{label confusions} among positive relations.
%%%The reasons are twofold. First, since the knowledge bases are usually far from perfect, the \DS generated negative data are often \textit{false negative}. And the inexact alignments between seed knowledge facts and unstructured text produces many  \textit{false positive} instances.
% }
%%%However our transition matrix has the ability to model all these three types of noise. To prevent overfitting and make the model \red{concentrate on the false negative and false positive noise??}\orange{(not sure about the problem)}, 
%We  thus restrict the transition matrix for bag level models to \blue{(why not sentence level?)} so that the diagonal, the first column and the first row of the transition matrix may not equal to zero\footnote{we assume that the index of \emph{No-Relation} is 0.}, \blue{acommodating  such noisy instances???}.
%%
%%
%%
%%%%%%%%%%%%%%%%%%%% omit for further journal publication  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
