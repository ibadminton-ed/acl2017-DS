\begin{abstract}
Distant supervision significantly reduces human efforts in constructing
training data for classification tasks by
automatically labeling data using knowledge learned from seed examples.
While promising,
this technique often introduces noise into the generated training data, which can
severely affect the performance of the learned model. In this paper, we take
a deep look at the application of distant supervision in relation extraction.
We show that the dynamic transition matrix can effectively characterize the noise of the distant supervision output.
To train the transition matrix, we develop a dynamic, curriculum learning based method to 
determine the matrix weights, without relying  on any direct supervision of the noise. 
We thoroughly evaluate our approach under a wide range of extraction scenarios. 
Experimental results show that our approach consistently improves the extraction results and outperforms 
the state-of-the-art in all evaluation scenarios. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Previous %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% and the experimental results show that it is possible to learn to model the noise without explicit guidance, and
% our proposed method can better characterize the underlying noise in the training data, leading to consistent improvements over
% the state of the art in various settings.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%in distantly supervised relation extraction and improve extraction performance in various settings.
% \todo{I do not like the last sentence!!}

\end{abstract} 