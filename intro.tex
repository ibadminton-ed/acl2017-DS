\section{Introduction}

\todo{ZW: Start by saying DS is a powerful technique for performing relation extraction on a large text corpus where manually labeling every single sentence is impossible. (2) The quality of DS highly depends on the training examples, but it not always possible to have a perfectly labelled data set and noise is pervasive in training data. Therefore, DS-based RE has to work with noisy data. 
     (3)There have been attempts on modelling/reducing the noises in the training data set, but prior work are terrible... (4) We then move to talk about our key insights,  how fantastic our approach is and how does it go beyond the state-of-the-art. (5) Summarise our experimental results, saying that we beat the state-of-the-art by xx\%.}

%Distant supervision is a commonly used method to automatically generate noisy training data with human designed heuristics. This method has been employed in many tasks including sentiment classification \cite{go2009twitter}, named entity recognition \cite{ritter2011named} and relation extraction \cite{mintz2009distant}. However,

%Sometimes, the heuristic only consists of a simple rule. For example, \cite{read2005using} considers the smile emoticon and the frown emoticon to expression positive and negative sentiment respectively and build a sentiment classification dataset with this heuristic. Sometimes, the heuristic depends on an existing database. For example,

Distant supervision is a way of exploiting existing (prior) knowledge to construct training data for classification tasks, without relying on laborious human annotation.

The basic distant supervision paradigm lies in making proper assumptions according to a task, distilling feasible and effective rules from prior knowledge and applying those rules to automatically prepare training data. Successful distant supervision applications include, relation extraction \cite{mintz2009distant}, cross-lingual semantic analysis \cite{fang2016learning}, and so on. The former assumes that the sentences containing both the subject and the object of a (subject $subj$, relation $rel$, object $obj$) triple are support for the existence of relation $rel$ between $subj$ and $obj$, and aligns triples in knowledge base with free text to automatically create training data. The latter assumes that words of different languages which share similar meaning should have similar POS tags, and thus automatically create training data for low-resourced languages according to their English translations.

%translates the English POS tag training data to other languages to compensate the the problem of limited training data for low-resourced languages.

Distant supervision significantly reduces the cost of obtaining training data for these tasks. However, since the assumptions may be imperfect, it also inevitably brings noise to the training data.  Sometimes the positive data may actually be negative (\emph{false positive}), while sometimes the negative data may actually be positive (\emph{false negative}). Furthermore, sometimes there may also be confusion between positive labels (\emph{positive label confusion}). This noisy data may disturb the training procedure, and lead to a model with inaccurate performance.

We need to note that, the noise introduced by distant supervision is not random, and the input data may consist of useful clues for us to identify its noise pattern. In relation extraction, for example, some sentences labeled by distant supervision to express the relation \emph{place\_of\_birth} between a person and place actually only talks about the work place of the person. Since we also find many sentences labeled as \emph{place\_lived} talks about the person's work place, we can reasonably assume that if a sentence is talking about the work place of a person, although the real relation expressed by the sentence is \emph{place\_lived}, there is still some chance that it is erroneously labeled as \emph{place\_of\_birth} by distant supervision.

This observation shows that it is possible to identify the noise pattern by analyzing the input data. In this paper, we propose to dynamically produce a transition matrix $\mathbf{T}$ for each datum to model the transition from the true label to the observed label. Here $T_{ij}$ represents the conditional probability that the observed label is $j$ given the true label is $i$. Since the label modeled by the transition matrix can be both positive and negative, it actually has the ability to model all the three types of noise introduced by distant supervision.

%The difficulty of training the transition matrix lies in that the only supervision we can use is the noisy label of the data.

%To overcome the difficulty, we propose to combine curriculum learning and trace normalization over the transition matrix to train our model.

In this paper, we focus specifically on the relation extraction task. The data is noisy because not all sentences containing $subj$ and $obj$ support the ($subj$, $rel$, $obj$) triple. \todo{for example...} In previous literature, this noise is often implicitly handled by the \emph{at-least-one assumption} that at least one of the sentences containing both $subj$ and $obj$ support the ($subj$, $rel$, $obj$) triple. The  sentences that containing both $subj$ and $obj$ are therefore aggregated into a sentence bag, and the problem becomes classifying the relation expressed by the sentence bag instead \cite{riedel2010modeling,lin2016neural}.


%Since the dataset proposed by \cite{luo2016temporal}, which aims at extracting relations between entity and time, contains both reliable and unreliable data, we also experiment our transition matrix model in the situation with and without reliable data.

However, the at-least-one assumption is not perfect either, and therefore introduces bag level noise. First, if all the retrieved sentences do not support the ($subj$, $rel$, $obj$) triple, then this bag is false positive. Second, if the ($subj$, $rel$, $obj$) triple is true but is missing in the KB, then the bag is false negative.
%Many methods have been developed to deal with this problem \cite{min2013distant,ritter2013modeling,xu2013filling}.

We apply our transition matrix method to both sentence level and bag level models. We also propose to combine curriculum learning and trace normalization for training to deal with the lack of guidance over the noise. The experiments show that our transition matrix method improve both of these models in two datasets. By experimenting on the dataset proposed by \cite{luo2016temporal}, which contains both reliable and unreliable data, we show that our training procedure can make use of the prior knowledge of the data quality and help the transition matrix model the noise better. We find that, the at-least-one assumption works better than the sentence level transition matrix model if no prior knowledge of the data quality is used. However, if we know which data are reliable, the sentence level transition matrix model works significantly better than bag level transition models. This shows that, with some indirect guidance, explicitly modeling the noise works better than using heuristics to implicitly handle the noise.

% In this paper, we propose to use transition matrix to model these noises in a unified form. Specifically, we want to dynamically generate a transition matrix $\mathbf{T}$ for each datum to model the transition from the real relation to the noisy relation tagged by distant supervision. Here $T_{ij}$ represents the conditional probability that the true relation of this sentence (or sentence bag) is $j$ given the relation assigned by distant supervision is $i$. By applying the transition matrix to sentence level models, our method can model the noise rather than just trying to lower the influcence of noisy data as previous methods do using \emph{at-least-one assumption}. Therefore, our method has the potential to actually make use of the noise rather than just trying to get rid of them. If our transition matrix is applied to bag level models, it can model both the false negative and false positive noise. Different from previous bag level denoising models, our models works in the neural network framework rather than the probabilistic graphic model framework. \todo{polish the difference from false negative models}

% We experiment our transition matrix method with both sentence level models and bag level models in two public relation extraction datasets. The experiments show that our transition matrix method can improve the performance of all baseline models in both datasets. We also find that, if we do not have prior knowledge of the data quality, the bag level model performs better than the sentence level model. However, if we have both reliable and unreliable data, we can use this prior knowledge to further improve the transition matrix. Since the sentence level noise is more important than the bag level noise, the sentence level model outperforms the bag level model in this situation, which shows that modeling the noise works better than just trying to ignoring the noise.
